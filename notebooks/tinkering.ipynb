{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "\n",
    "import nltk\n",
    "import tqdm\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('universal_tagset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/VUA_DATA_PROC/'\n",
    "VUA_DATA_PATH = '../data/VUA_DATA_RAW/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_csv(VUA_DATA_PATH+'vuamc_corpus_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a1e-fragment01</td>\n",
       "      <td>1</td>\n",
       "      <td>Latest corporate unbundler M_reveals laid-back...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a1e-fragment01</td>\n",
       "      <td>2</td>\n",
       "      <td>By FRANK KANE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a1e-fragment01</td>\n",
       "      <td>3</td>\n",
       "      <td>IT SEEMS that Roland Franklin , the latest unb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a1e-fragment01</td>\n",
       "      <td>4</td>\n",
       "      <td>He has not properly investigated the M_target ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a1e-fragment01</td>\n",
       "      <td>5</td>\n",
       "      <td>The 63-year-old M_head of Pembridge Investment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12117</th>\n",
       "      <td>kcv-fragment42</td>\n",
       "      <td>4664</td>\n",
       "      <td>Perhaps when they come back they 've M_got six...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12118</th>\n",
       "      <td>kcv-fragment42</td>\n",
       "      <td>4665</td>\n",
       "      <td>I know .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12119</th>\n",
       "      <td>kcv-fragment42</td>\n",
       "      <td>4666</td>\n",
       "      <td>Some else 's sitting at their desk ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12120</th>\n",
       "      <td>kcv-fragment42</td>\n",
       "      <td>4667</td>\n",
       "      <td>Well not you know cleaning so I do n't know wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12121</th>\n",
       "      <td>kcv-fragment42</td>\n",
       "      <td>4668</td>\n",
       "      <td>Oh well if you 're here M_that 's all right</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12122 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               txt_id sentence_id  \\\n",
       "0      a1e-fragment01           1   \n",
       "1      a1e-fragment01           2   \n",
       "2      a1e-fragment01           3   \n",
       "3      a1e-fragment01           4   \n",
       "4      a1e-fragment01           5   \n",
       "...               ...         ...   \n",
       "12117  kcv-fragment42        4664   \n",
       "12118  kcv-fragment42        4665   \n",
       "12119  kcv-fragment42        4666   \n",
       "12120  kcv-fragment42        4667   \n",
       "12121  kcv-fragment42        4668   \n",
       "\n",
       "                                            sentence_txt  \n",
       "0      Latest corporate unbundler M_reveals laid-back...  \n",
       "1                                          By FRANK KANE  \n",
       "2      IT SEEMS that Roland Franklin , the latest unb...  \n",
       "3      He has not properly investigated the M_target ...  \n",
       "4      The 63-year-old M_head of Pembridge Investment...  \n",
       "...                                                  ...  \n",
       "12117  Perhaps when they come back they 've M_got six...  \n",
       "12118                                           I know .  \n",
       "12119               Some else 's sitting at their desk ?  \n",
       "12120  Well not you know cleaning so I do n't know wh...  \n",
       "12121        Oh well if you 're here M_that 's all right  \n",
       "\n",
       "[12122 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(DATA_PATH, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_vua_data(data_file, save_file):\n",
    "   data= pd.read_csv(VUA_DATA_PATH+data_file)\n",
    "\n",
    "   sentences = []\n",
    "   pos_tags = []\n",
    "   labels = []\n",
    "\n",
    "   for row in data.values:\n",
    "      sen = str(row[2]).split(' ')\n",
    "      sen_len = len(sen)\n",
    "\n",
    "      cleaned_sen = [w.replace('M_', '') if w.startswith('M_') else w for w in sen]\n",
    "      pos_tag = [nltk.tag.pos_tag([w], tagset='universal')[0][1] for w in cleaned_sen]\n",
    "      labels_arr = [1 if w.startswith('M_') else 0 for w in sen]\n",
    "\n",
    "      cleaned_sen = ' '.join(cleaned_sen).strip()\n",
    "      sentences.append(cleaned_sen)\n",
    "      labels.append(labels_arr)\n",
    "      pos_tags.append(pos_tag)\n",
    "      \n",
    "      assert len(pos_tag) == sen_len , \"number of position tags for sentence should be equal to the length of sentence\"\n",
    "\n",
    "\n",
    "   df = pd.DataFrame({'txt_id': data['txt_id'].values,\n",
    "                      'sen_idx': data['sentence_id'].values,\n",
    "                      'sentence': sentences,\n",
    "                      'label_seq': labels,\n",
    "                      'pos_seq': pos_tags,\n",
    "                      'labeled_sentence': data['sentence_txt'].values\n",
    "                    #   'genre': np.empty_like(labels)\n",
    "                      })\n",
    "   \n",
    "   df.to_csv(DATA_PATH+save_file, index=False)\n",
    "\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(read_path):\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    df = pd.read_csv(DATA_PATH + read_path)\n",
    "    df = df[df['sentence'].notna()]\n",
    "\n",
    "    ratio = int(len(df)/10)\n",
    "    df = df.sample(frac = 1, random_state= 42)\n",
    "\n",
    "    val_df = df[:ratio]\n",
    "    train_df = df[ratio:]\n",
    "\n",
    "    val_path = read_path[:-4]+ '_val.csv'\n",
    "    train_path = read_path[: -4] + '_train.csv'\n",
    "\n",
    "    val_df.to_csv(DATA_PATH + val_path, index = False)\n",
    "    train_df.to_csv(DATA_PATH + train_path, index= False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_vua_data('vuamc_corpus_train.csv', 'VUA_corpus.csv')\n",
    "prepare_vua_data('vuamc_corpus_test.csv', 'VUA_corpus_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_split('VUA_corpus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f'{DATA_PATH}VUA_corpus_train.csv')\n",
    "val_df = pd.read_csv(f'{DATA_PATH}VUA_corpus_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt_id</th>\n",
       "      <th>sen_idx</th>\n",
       "      <th>sentence</th>\n",
       "      <th>label_seq</th>\n",
       "      <th>pos_seq</th>\n",
       "      <th>labeled_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clp-fragment01</td>\n",
       "      <td>764</td>\n",
       "      <td>Task analysis can be very expensive in skilled...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, ...</td>\n",
       "      <td>['NOUN', 'NOUN', 'VERB', 'VERB', 'ADV', 'ADJ',...</td>\n",
       "      <td>Task analysis can be very expensive M_in skill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kcc-fragment02</td>\n",
       "      <td>25</td>\n",
       "      <td>Well I , I , I asked him what he wanted for Ch...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>['ADV', 'PRON', '.', 'PRON', '.', 'PRON', 'VER...</td>\n",
       "      <td>Well I , I , I asked him what he wanted for Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kcu-fragment02</td>\n",
       "      <td>1489</td>\n",
       "      <td>Now that 's right !</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>['ADV', 'ADP', 'PRT', 'NOUN', '.']</td>\n",
       "      <td>Now M_that 's right !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ajf-fragment07</td>\n",
       "      <td>228</td>\n",
       "      <td>The NAACP denounces The Silence of the Lambs b...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "      <td>['DET', 'NOUN', 'NOUN', 'DET', 'NOUN', 'ADP', ...</td>\n",
       "      <td>The NAACP M_denounces The Silence of the Lambs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amm-fragment02</td>\n",
       "      <td>1649</td>\n",
       "      <td>The convex , middle part of the thorax contain...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "      <td>['DET', 'NOUN', '.', 'NOUN', 'NOUN', 'ADP', 'D...</td>\n",
       "      <td>The convex , middle part of the thorax contain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10894</th>\n",
       "      <td>kcv-fragment42</td>\n",
       "      <td>4524</td>\n",
       "      <td>With who ?</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>['ADP', 'PRON', '.']</td>\n",
       "      <td>M_With who ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10895</th>\n",
       "      <td>crs-fragment01</td>\n",
       "      <td>15</td>\n",
       "      <td>Between 1982 and 1988 provision gradually incr...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>['NOUN', 'NUM', 'CONJ', 'NUM', 'NOUN', 'ADV', ...</td>\n",
       "      <td>M_Between 1982 and 1988 provision gradually in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10896</th>\n",
       "      <td>ew1-fragment01</td>\n",
       "      <td>12</td>\n",
       "      <td>Long was supported by the bulk of the English ...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>['ADV', 'VERB', 'VERB', 'ADP', 'DET', 'NOUN', ...</td>\n",
       "      <td>Long was M_supported by the M_bulk of the Engl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10897</th>\n",
       "      <td>a3p-fragment09</td>\n",
       "      <td>183</td>\n",
       "      <td>We were quite alone and the great church , the...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>['PRON', 'VERB', 'ADV', 'ADV', 'CONJ', 'DET', ...</td>\n",
       "      <td>We were quite alone and the great church , the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10898</th>\n",
       "      <td>kbc-fragment13</td>\n",
       "      <td>5992</td>\n",
       "      <td>It was n't months Gordon .</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>['PRON', 'VERB', 'ADV', 'NOUN', 'NOUN', '.']</td>\n",
       "      <td>It was n't months Gordon .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10899 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               txt_id sen_idx  \\\n",
       "0      clp-fragment01     764   \n",
       "1      kcc-fragment02      25   \n",
       "2      kcu-fragment02    1489   \n",
       "3      ajf-fragment07     228   \n",
       "4      amm-fragment02    1649   \n",
       "...               ...     ...   \n",
       "10894  kcv-fragment42    4524   \n",
       "10895  crs-fragment01      15   \n",
       "10896  ew1-fragment01      12   \n",
       "10897  a3p-fragment09     183   \n",
       "10898  kbc-fragment13    5992   \n",
       "\n",
       "                                                sentence  \\\n",
       "0      Task analysis can be very expensive in skilled...   \n",
       "1      Well I , I , I asked him what he wanted for Ch...   \n",
       "2                                    Now that 's right !   \n",
       "3      The NAACP denounces The Silence of the Lambs b...   \n",
       "4      The convex , middle part of the thorax contain...   \n",
       "...                                                  ...   \n",
       "10894                                         With who ?   \n",
       "10895  Between 1982 and 1988 provision gradually incr...   \n",
       "10896  Long was supported by the bulk of the English ...   \n",
       "10897  We were quite alone and the great church , the...   \n",
       "10898                         It was n't months Gordon .   \n",
       "\n",
       "                                               label_seq  \\\n",
       "0      [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, ...   \n",
       "1                [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "2                                        [0, 1, 0, 0, 0]   \n",
       "3      [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...   \n",
       "4      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...   \n",
       "...                                                  ...   \n",
       "10894                                          [1, 0, 0]   \n",
       "10895  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...   \n",
       "10896  [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...   \n",
       "10897  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "10898                                 [0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                                                 pos_seq  \\\n",
       "0      ['NOUN', 'NOUN', 'VERB', 'VERB', 'ADV', 'ADJ',...   \n",
       "1      ['ADV', 'PRON', '.', 'PRON', '.', 'PRON', 'VER...   \n",
       "2                     ['ADV', 'ADP', 'PRT', 'NOUN', '.']   \n",
       "3      ['DET', 'NOUN', 'NOUN', 'DET', 'NOUN', 'ADP', ...   \n",
       "4      ['DET', 'NOUN', '.', 'NOUN', 'NOUN', 'ADP', 'D...   \n",
       "...                                                  ...   \n",
       "10894                               ['ADP', 'PRON', '.']   \n",
       "10895  ['NOUN', 'NUM', 'CONJ', 'NUM', 'NOUN', 'ADV', ...   \n",
       "10896  ['ADV', 'VERB', 'VERB', 'ADP', 'DET', 'NOUN', ...   \n",
       "10897  ['PRON', 'VERB', 'ADV', 'ADV', 'CONJ', 'DET', ...   \n",
       "10898       ['PRON', 'VERB', 'ADV', 'NOUN', 'NOUN', '.']   \n",
       "\n",
       "                                        labeled_sentence  \n",
       "0      Task analysis can be very expensive M_in skill...  \n",
       "1      Well I , I , I asked him what he wanted for Ch...  \n",
       "2                                  Now M_that 's right !  \n",
       "3      The NAACP M_denounces The Silence of the Lambs...  \n",
       "4      The convex , middle part of the thorax contain...  \n",
       "...                                                  ...  \n",
       "10894                                       M_With who ?  \n",
       "10895  M_Between 1982 and 1988 provision gradually in...  \n",
       "10896  Long was M_supported by the M_bulk of the Engl...  \n",
       "10897  We were quite alone and the great church , the...  \n",
       "10898                         It was n't months Gordon .  \n",
       "\n",
       "[10899 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt_id</th>\n",
       "      <th>sen_idx</th>\n",
       "      <th>sentence</th>\n",
       "      <th>label_seq</th>\n",
       "      <th>pos_seq</th>\n",
       "      <th>labeled_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ab9-fragment03</td>\n",
       "      <td>810</td>\n",
       "      <td>He was a sensible and capable boy , an eldest ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>['PRON', 'VERB', 'DET', 'ADJ', 'CONJ', 'ADJ', ...</td>\n",
       "      <td>He was a sensible and capable boy , an eldest ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kbj-fragment17</td>\n",
       "      <td>1606</td>\n",
       "      <td>Write it out on a piece of paper and you 'll a...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>['VERB', 'PRON', 'ADP', 'ADP', 'DET', 'NOUN', ...</td>\n",
       "      <td>Write it out on a piece of paper and you 'll a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kbh-fragment09</td>\n",
       "      <td>1196</td>\n",
       "      <td>Alright stop it then keep that</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>['NOUN', 'NOUN', 'PRON', 'ADV', 'VERB', 'ADP']</td>\n",
       "      <td>Alright M_stop it then keep that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kbw-fragment04</td>\n",
       "      <td>2581</td>\n",
       "      <td>Jonathan .</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>['NOUN', '.']</td>\n",
       "      <td>Jonathan .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b1g-fragment02</td>\n",
       "      <td>806</td>\n",
       "      <td>Monitoring of the state of and the changes in ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>['VERB', 'ADP', 'DET', 'NOUN', 'ADP', 'CONJ', ...</td>\n",
       "      <td>Monitoring of the state of and the changes in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>kbw-fragment04</td>\n",
       "      <td>2471</td>\n",
       "      <td>Ah .</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>['NOUN', '.']</td>\n",
       "      <td>Ah .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>as6-fragment02</td>\n",
       "      <td>416</td>\n",
       "      <td>As pointed out earlier , the ‘ social causes ’...</td>\n",
       "      <td>[0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>['ADP', 'VERB', 'ADP', 'ADV', '.', 'DET', 'NOU...</td>\n",
       "      <td>As M_pointed M_out earlier , the ‘ social caus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1207</th>\n",
       "      <td>g0l-fragment01</td>\n",
       "      <td>324</td>\n",
       "      <td>He burst out laughing .</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>['PRON', 'NOUN', 'ADP', 'VERB', '.']</td>\n",
       "      <td>He burst out laughing .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>kbh-fragment03</td>\n",
       "      <td>285</td>\n",
       "      <td>Yeah , the Robots .</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>['NOUN', '.', 'DET', 'NOUN', '.']</td>\n",
       "      <td>Yeah , the Robots .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>kbw-fragment17</td>\n",
       "      <td>6071</td>\n",
       "      <td>How much ?</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>['ADV', 'ADJ', '.']</td>\n",
       "      <td>How much ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1210 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              txt_id  sen_idx  \\\n",
       "0     ab9-fragment03      810   \n",
       "1     kbj-fragment17     1606   \n",
       "2     kbh-fragment09     1196   \n",
       "3     kbw-fragment04     2581   \n",
       "4     b1g-fragment02      806   \n",
       "...              ...      ...   \n",
       "1205  kbw-fragment04     2471   \n",
       "1206  as6-fragment02      416   \n",
       "1207  g0l-fragment01      324   \n",
       "1208  kbh-fragment03      285   \n",
       "1209  kbw-fragment17     6071   \n",
       "\n",
       "                                               sentence  \\\n",
       "0     He was a sensible and capable boy , an eldest ...   \n",
       "1     Write it out on a piece of paper and you 'll a...   \n",
       "2                        Alright stop it then keep that   \n",
       "3                                            Jonathan .   \n",
       "4     Monitoring of the state of and the changes in ...   \n",
       "...                                                 ...   \n",
       "1205                                               Ah .   \n",
       "1206  As pointed out earlier , the ‘ social causes ’...   \n",
       "1207                            He burst out laughing .   \n",
       "1208                                Yeah , the Robots .   \n",
       "1209                                         How much ?   \n",
       "\n",
       "                                              label_seq  \\\n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2                                    [0, 1, 0, 0, 0, 0]   \n",
       "3                                                [0, 0]   \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                 ...   \n",
       "1205                                             [0, 0]   \n",
       "1206  [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...   \n",
       "1207                                    [0, 0, 0, 0, 0]   \n",
       "1208                                    [0, 0, 0, 0, 0]   \n",
       "1209                                          [0, 0, 0]   \n",
       "\n",
       "                                                pos_seq  \\\n",
       "0     ['PRON', 'VERB', 'DET', 'ADJ', 'CONJ', 'ADJ', ...   \n",
       "1     ['VERB', 'PRON', 'ADP', 'ADP', 'DET', 'NOUN', ...   \n",
       "2        ['NOUN', 'NOUN', 'PRON', 'ADV', 'VERB', 'ADP']   \n",
       "3                                         ['NOUN', '.']   \n",
       "4     ['VERB', 'ADP', 'DET', 'NOUN', 'ADP', 'CONJ', ...   \n",
       "...                                                 ...   \n",
       "1205                                      ['NOUN', '.']   \n",
       "1206  ['ADP', 'VERB', 'ADP', 'ADV', '.', 'DET', 'NOU...   \n",
       "1207               ['PRON', 'NOUN', 'ADP', 'VERB', '.']   \n",
       "1208                  ['NOUN', '.', 'DET', 'NOUN', '.']   \n",
       "1209                                ['ADV', 'ADJ', '.']   \n",
       "\n",
       "                                       labeled_sentence  \n",
       "0     He was a sensible and capable boy , an eldest ...  \n",
       "1     Write it out on a piece of paper and you 'll a...  \n",
       "2                      Alright M_stop it then keep that  \n",
       "3                                            Jonathan .  \n",
       "4     Monitoring of the state of and the changes in ...  \n",
       "...                                                 ...  \n",
       "1205                                               Ah .  \n",
       "1206  As M_pointed M_out earlier , the ‘ social caus...  \n",
       "1207                            He burst out laughing .  \n",
       "1208                                Yeah , the Robots .  \n",
       "1209                                         How much ?  \n",
       "\n",
       "[1210 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(VUA_DATA_PATH + 'all_pos_tokens.csv', header = None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a1h-fragment06_114_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a1h-fragment06_114_3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a1h-fragment06_114_4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a1h-fragment06_115_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a1h-fragment06_115_3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72606</th>\n",
       "      <td>as6-fragment02_441_21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72607</th>\n",
       "      <td>as6-fragment02_441_25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72608</th>\n",
       "      <td>as6-fragment02_441_27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72609</th>\n",
       "      <td>as6-fragment02_441_30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72610</th>\n",
       "      <td>as6-fragment02_441_32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72611 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0  1\n",
       "0       a1h-fragment06_114_1  0\n",
       "1       a1h-fragment06_114_3  0\n",
       "2       a1h-fragment06_114_4  0\n",
       "3       a1h-fragment06_115_2  0\n",
       "4       a1h-fragment06_115_3  0\n",
       "...                      ... ..\n",
       "72606  as6-fragment02_441_21  0\n",
       "72607  as6-fragment02_441_25  1\n",
       "72608  as6-fragment02_441_27  0\n",
       "72609  as6-fragment02_441_30  0\n",
       "72610  as6-fragment02_441_32  0\n",
       "\n",
       "[72611 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_tokens_data(label_file, save_tokens_file):\n",
    "\n",
    "    labels = pd.read_csv(VUA_DATA_PATH + label_file, header = None )\n",
    "\n",
    "    dict = {}\n",
    "\n",
    "    for row in labels.values:\n",
    "        text_id = row[0].split('_')\n",
    "        txt_id  = text_id[0]\n",
    "        sen_id = text_id[1]\n",
    "\n",
    "        offset = int(text_id[2])-1\n",
    "\n",
    "        if txt_id not in dict:\n",
    "            dict[txt_id] = {}\n",
    "\n",
    "        if sen_id not in dict[txt_id]:\n",
    "            dict[txt_id][sen_id] = [offset]\n",
    "        else:\n",
    "            dict[txt_id][sen_id].append(offset)\n",
    "\n",
    "        with open(DATA_PATH + save_tokens_file, 'wb+') as f:\n",
    "            pickle.dump(dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokens for test data\n",
    "prepare_tokens_data('all_pos_tokens_test.csv', 'all_pos_tokens_test.pkl')\n",
    "prepare_tokens_data('verb_tokens_test.csv', 'verb_tokens_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/VUA_DATA_PROC/verb_tokens_test.pkl', 'rb') as pickle_file:\n",
    "    content = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _elmo_vectors(read_path, save_path):\n",
    "\n",
    "#     df = pd.read_csv(DATA_PATH + read_path)\n",
    "\n",
    "#     dict = {}\n",
    "\n",
    "#     txt_ids = df['txt_id'].values\n",
    "#     sen_ids = df['sen_idx'].values\n",
    "#     sentences = df['sentence'].values\n",
    "#     assert len(txt_ids) == len(sentences)\n",
    "\n",
    "#     batch_sentences = [sentences[i : min(i+64, len(sentences))] for i in range(0, len(sentences, 64))]\n",
    "#     batch_txt_ids = [txt_ids[i:min(i+64, len(txt_ids))] for i in range(0, len(txt_ids), 64)]\n",
    "#     batch_sen_ids = [sen_ids[i:min(i+64, len(sen_ids))] for i in range(0, len(sen_ids), 64)]\n",
    "#     batch_sen_len = [[len(sen.split(' ')) for sen in batch_sen] for batch_sen in batch_sentences]\n",
    "\n",
    "#     assert len(batch_sentences) == len(batch_txt_ids)\n",
    "\n",
    "#     for i in tqdm(range(len(batch_sen_ids))):\n",
    "#         sen = batch_sentences [i]\n",
    "#         txt_id = batch_txt_ids [i]\n",
    "#         sen_id = batch_sen_ids[i]\n",
    "#         sen_len = batch_sen_len[i]\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
